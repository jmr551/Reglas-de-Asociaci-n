{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Capítulo 4: Algoritmo Apriori\n",
        "\n",
        "## 4.1 Fundamentos Teóricos\n",
        "\n",
        "El **Algoritmo Apriori** es uno de los algoritmos más influyentes para la minería de **itemsets frecuentes** y la generación de **reglas de asociación**. Fue propuesto por **Rakesh Agrawal** y **Ramakrishnan Srikant** en 1994. Apriori utiliza la propiedad de antimonotonía del soporte, conocida como el **Teorema Apriori**, para reducir eficientemente el espacio de búsqueda.\n",
        "\n",
        "### 4.1.1 Teorema Apriori\n",
        "\n",
        "#### Definición del Teorema\n",
        "\n",
        "El **Teorema Apriori** establece que:\n",
        "\n",
        "> *Si un itemset es frecuente, entonces todos sus subconjuntos no vacíos también deben ser frecuentes.*\n",
        "\n",
        "Equivalente a:\n",
        "\n",
        "> *Si un itemset es infrecuente, entonces todos sus superconjuntos también son infrecuentes.*\n",
        "\n",
        "#### Implicaciones del Teorema\n",
        "\n",
        "- **Antimonotonía del Soporte**: El soporte de un itemset no puede ser mayor que el soporte de cualquiera de sus subconjuntos.\n",
        "- **Pruning Efectivo**: Permite descartar tempranamente itemsets que no pueden ser frecuentes, reduciendo significativamente el número de candidatos a considerar.\n",
        "\n",
        "#### Demostración Intuitiva\n",
        "\n",
        "Consideremos que si un itemset $ X $ ocurre en $ k $ transacciones, cualquier superconjunto $ X' \\supset X $ solo puede ocurrir en esas mismas $ k $ transacciones o en un subconjunto de ellas. Por lo tanto, el soporte de $ X' $ es menor o igual al soporte de $ X $.\n",
        "\n",
        "### 4.1.2 Generación de Candidatos y Pruning\n",
        "\n",
        "El algoritmo Apriori opera en iteraciones, generando itemsets frecuentes de tamaño creciente en cada paso.\n",
        "\n",
        "#### Pasos del Algoritmo Apriori\n",
        "\n",
        "1. **Generación de Itemsets Frecuentes de Tamaño 1 ($L_1 $)**:\n",
        "   - Calcular el soporte de todos los itemsets individuales (1-ítems).\n",
        "   - Seleccionar aquellos que cumplen el umbral mínimo de soporte.\n",
        "\n",
        "2. **Iteración $ k $ (para $ k \\geq 2 $)**:\n",
        "   - **Generación de Candidatos ($ C_k $)**:\n",
        "     - Unir los itemsets frecuentes de tamaño $ k-1 $ para formar candidatos de tamaño $ k $.\n",
        "     - $ C_k = L_{k-1} $ unido consigo mismo.\n",
        "   - **Pruning de Candidatos**:\n",
        "     - Eliminar candidatos que tengan subconjuntos infrecuentes.\n",
        "     - Aplicar el Teorema Apriori para reducir el número de candidatos.\n",
        "   - **Cálculo de Soportes**:\n",
        "     - Contar las ocurrencias de cada candidato en las transacciones.\n",
        "   - **Generación de Itemsets Frecuentes ($ L_k $)**:\n",
        "     - Seleccionar los candidatos que cumplen el umbral mínimo de soporte.\n",
        "   - Repetir el proceso hasta que no se puedan generar más itemsets frecuentes.\n",
        "\n",
        "#### Ejemplo de Generación y Pruning\n",
        "\n",
        "Supongamos que $ L_2 = \\{ \\{A, B\\}, \\{A, C\\}, \\{B, C\\} \\} $.\n",
        "\n",
        "- **Generación de Candidatos $ C_3 $**:\n",
        "  - Unimos $ L_2 $ consigo mismo:\n",
        "    - \\{A, B\\} ∪ \\{A, C\\} ⇒ \\{A, B, C\\}\n",
        "    - \\{A, B\\} ∪ \\{B, C\\} ⇒ \\{A, B, C\\}\n",
        "    - \\{A, C\\} ∪ \\{B, C\\} ⇒ \\{A, B, C\\}\n",
        "  - Obtenemos $ C_3 = \\{ \\{A, B, C\\} \\} $.\n",
        "- **Pruning**:\n",
        "  - Verificamos si todos los subconjuntos de tamaño $ k-1 $ son frecuentes.\n",
        "  - Los subconjuntos de \\{A, B, C\\} son:\n",
        "    - \\{A, B\\}, \\{A, C\\}, \\{B, C\\}\n",
        "  - Si todos están en $ L_2 $, mantenemos el candidato.\n",
        "\n",
        "## 4.2 Implementación Manual en Python\n",
        "\n",
        "### 4.2.1 Paso a Paso del Algoritmo\n",
        "\n",
        "Implementaremos el algoritmo Apriori siguiendo estos pasos:\n",
        "\n",
        "1. **Preparar las Transacciones**: Representar los datos en una estructura adecuada.\n",
        "2. **Encontrar Itemsets Frecuentes de Tamaño 1 ($ L_1 $)**:\n",
        "   - Calcular el soporte de cada ítem.\n",
        "   - Filtrar los ítems que cumplen el soporte mínimo.\n",
        "3. **Iterar para $ k \\geq 2 $**:\n",
        "   - **Generar Candidatos $( C_k )$**: Combinar los itemsets frecuentes de tamaño $ k-1 $.\n",
        "   - **Pruning**: Eliminar candidatos cuyos subconjuntos no sean frecuentes.\n",
        "   - **Calcular Soportes**: Contar las ocurrencias de los candidatos en las transacciones.\n",
        "   - **Generar Itemsets Frecuentes $( L_k )$**: Filtrar candidatos que cumplen el soporte mínimo.\n",
        "4. **Terminar Cuando No Se Generen Más Itemsets Frecuentes**.\n",
        "\n",
        "### 4.2.2 Código desde Cero\n",
        "\n",
        "#### Paso 1: Preparar las Transacciones\n",
        "\n",
        "Utilizaremos el conjunto de transacciones del Capítulo 2."
      ],
      "metadata": {
        "id": "RvxbKFKCaFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transacciones = [\n",
        "    {'Leche', 'Pan'},\n",
        "    {'Leche', 'Pañales', 'Cerveza', 'Huevos'},\n",
        "    {'Leche', 'Pan', 'Pañales', 'Cerveza'},\n",
        "    {'Pan', 'Pañales', 'Cerveza'},\n",
        "    {'Leche', 'Pan', 'Cerveza', 'Coca-Cola'}\n",
        "]\n"
      ],
      "metadata": {
        "id": "v_-mC3A9aFms"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Paso 2: Definir Funciones Básicas"
      ],
      "metadata": {
        "id": "LEB0vUcsho6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_itemsets_1(transacciones):\n",
        "    items_unicos = set()\n",
        "    for transaccion in transacciones:\n",
        "        items_unicos.update(transaccion)\n",
        "    itemsets_1 = [{item} for item in items_unicos]\n",
        "    return itemsets_1\n",
        "\n",
        "def calcular_soportes(transacciones, itemsets):\n",
        "    soporte_itemsets = {}\n",
        "    num_transacciones = len(transacciones)\n",
        "    for itemset in itemsets:\n",
        "        conteo = sum(1 for transaccion in transacciones if itemset.issubset(transaccion))\n",
        "        soporte = conteo / num_transacciones\n",
        "        soporte_itemsets[frozenset(itemset)] = soporte\n",
        "    return soporte_itemsets"
      ],
      "metadata": {
        "id": "UMEMdS7whowl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Paso 3: Implementar el Algoritmo Apriori"
      ],
      "metadata": {
        "id": "ikL29uhRkBN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_candidatos(previos_frecuentes, k):\n",
        "    candidatos = []\n",
        "    len_previos = len(previos_frecuentes)\n",
        "    for i in range(len_previos):\n",
        "        for j in range(i + 1, len_previos):\n",
        "            l1 = previos_frecuentes[i]\n",
        "            l2 = previos_frecuentes[j]\n",
        "            # Verificar si l1 y l2 tienen k-2 elementos en común\n",
        "            if len(l1.intersection(l2)) == k - 2:\n",
        "                nuevo_candidato = l1 | l2\n",
        "                if nuevo_candidato not in candidatos:\n",
        "                    candidatos.append(nuevo_candidato)\n",
        "    return candidatos\n",
        "\n",
        "def pruning(candidatos, previos_frecuentes):\n",
        "    candidatos_podados = []\n",
        "    previos_frecuentes_set = set(previos_frecuentes)\n",
        "    for candidato in candidatos:\n",
        "        subconjuntos = [candidato - {item} for item in candidato]\n",
        "        if all(frozenset(subconjunto) in previos_frecuentes_set for subconjunto in subconjuntos):\n",
        "            candidatos_podados.append(candidato)\n",
        "    return candidatos_podados\n",
        "\n",
        "def apriori(transacciones, min_soporte):\n",
        "    # Paso 1: Generar itemsets frecuentes de tamaño 1\n",
        "    itemsets_1 = obtener_itemsets_1(transacciones)\n",
        "    soporte_1 = calcular_soportes(transacciones, itemsets_1)\n",
        "    L1 = [itemset for itemset in soporte_1 if soporte_1[itemset] >= min_soporte]\n",
        "    soporte_total = soporte_1.copy()\n",
        "    frecuentes = [L1]\n",
        "    k = 2\n",
        "    while len(frecuentes[k-2]) > 0:\n",
        "        # Generar candidatos Ck\n",
        "        candidatos = generar_candidatos([set(itemset) for itemset in frecuentes[k-2]], k)\n",
        "        # Pruning\n",
        "        candidatos = pruning(candidatos, frecuentes[k-2])\n",
        "        # Calcular soportes\n",
        "        soporte_k = calcular_soportes(transacciones, candidatos)\n",
        "        # Generar Lk\n",
        "        Lk = [itemset for itemset in soporte_k if soporte_k[itemset] >= min_soporte]\n",
        "        # Actualizar soporte total\n",
        "        soporte_total.update(soporte_k)\n",
        "        frecuentes.append(Lk)\n",
        "        k += 1\n",
        "    return frecuentes, soporte_total"
      ],
      "metadata": {
        "id": "5zYSp4JOkBGL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Paso 4: Ejecutar el Algoritmo"
      ],
      "metadata": {
        "id": "IHVhhXvw0s40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_soporte = 0.6  # Umbral mínimo de soporte\n",
        "frecuentes, soporte_total = apriori(transacciones, min_soporte)\n",
        "\n",
        "# Mostrar los itemsets frecuentes\n",
        "print(\"Itemsets frecuentes encontrados:\")\n",
        "for k in range(len(frecuentes)):\n",
        "    if frecuentes[k]:\n",
        "        print(f\"\\nFrecuentes de tamaño {k+1}:\")\n",
        "        for itemset in frecuentes[k]:\n",
        "            items = set(itemset)\n",
        "            soporte = soporte_total[itemset]\n",
        "            print(f\"{items}: {soporte:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdULyfCJ0svT",
        "outputId": "cea58962-3961-4041-c7f7-05466cc6018d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Itemsets frecuentes encontrados:\n",
            "\n",
            "Frecuentes de tamaño 1:\n",
            "{'Pan'}: 0.80\n",
            "{'Leche'}: 0.80\n",
            "{'Pañales'}: 0.60\n",
            "{'Cerveza'}: 0.80\n",
            "\n",
            "Frecuentes de tamaño 2:\n",
            "{'Pan', 'Leche'}: 0.60\n",
            "{'Cerveza', 'Pan'}: 0.60\n",
            "{'Cerveza', 'Leche'}: 0.60\n",
            "{'Pañales', 'Cerveza'}: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Salida:**\n",
        "\n",
        "```\n",
        "Itemsets frecuentes encontrados:\n",
        "\n",
        "Frecuentes de tamaño 1:\n",
        "{'Pan'}: 0.80\n",
        "{'Leche'}: 0.80\n",
        "{'Pañales'}: 0.60\n",
        "{'Cerveza'}: 0.80\n",
        "\n",
        "Frecuentes de tamaño 2:\n",
        "{'Pan', 'Leche'}: 0.60\n",
        "{'Cerveza', 'Pan'}: 0.60\n",
        "{'Cerveza', 'Leche'}: 0.60\n",
        "{'Pañales', 'Cerveza'}: 0.60\n",
        "```\n",
        "\n",
        "#### Paso 5: Interpretación de Resultados\n",
        "\n",
        "- Los ítems individuales más frecuentes son **Leche**, **Pan** y **Cerveza**, cada uno con un soporte de 0.80, y **Pañales** con un soporte de 0.60.\n",
        "- Los pares frecuentes incluyen combinaciones de estos ítems con un soporte de 0.60.\n",
        "\n",
        "## 4.3 Análisis de Eficiencia y Mejora con Pruning\n",
        "\n",
        "### 4.3.1 Demostración Práctica de la Mejora\n",
        "\n",
        "#### Sin Pruning\n",
        "\n",
        "Si no aplicáramos el pruning, el algoritmo consideraría todos los posibles candidatos en cada iteración, lo que incrementaría exponencialmente el número de itemsets a evaluar.\n",
        "\n",
        "**Ejemplo:**\n",
        "\n",
        "En la generación de candidatos de tamaño 3 sin pruning, generaríamos todas las combinaciones posibles de los itemsets frecuentes de tamaño 2, incluso si algunos de sus subconjuntos no son frecuentes.\n",
        "\n",
        "#### Con Pruning (Usando el Teorema Apriori)\n",
        "\n",
        "Al aplicar el pruning:\n",
        "\n",
        "- **Reducción de Candidatos**: Solo se consideran aquellos candidatos cuyos todos los subconjuntos son frecuentes.\n",
        "- **Ahorro Computacional**: Menos candidatos implican menos cálculos de soporte y menos iteraciones.\n",
        "\n",
        "#### Comparación Práctica\n",
        "\n",
        "Implementemos una versión del algoritmo sin aplicar el pruning y comparemos el número de candidatos generados."
      ],
      "metadata": {
        "id": "exsewKj_1Yqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_candidatos_sin_pruning(previos_frecuentes, k):\n",
        "    candidatos = []\n",
        "    len_previos = len(previos_frecuentes)\n",
        "    for i in range(len_previos):\n",
        "        for j in range(i+1, len_previos):\n",
        "            candidato = previos_frecuentes[i] | previos_frecuentes[j]\n",
        "            if len(candidato) == k and candidato not in candidatos:\n",
        "                candidatos.append(candidato)\n",
        "    return candidatos\n",
        "\n",
        "def apriori_sin_pruning(transacciones, min_soporte):\n",
        "    # Paso 1: Generar itemsets frecuentes de tamaño 1\n",
        "    itemsets_1 = obtener_itemsets_1(transacciones)\n",
        "    soporte_1 = calcular_soportes(transacciones, itemsets_1)\n",
        "    L1 = [itemset for itemset in soporte_1 if soporte_1[itemset] >= min_soporte]\n",
        "    soporte_total = soporte_1.copy()\n",
        "    frecuentes = [L1]\n",
        "    k = 2\n",
        "    while len(frecuentes[k-2]) > 0:\n",
        "        # Generar candidatos Ck sin pruning\n",
        "        candidatos = generar_candidatos_sin_pruning([set(itemset) for itemset in frecuentes[k-2]], k)\n",
        "        # Calcular soportes\n",
        "        soporte_k = calcular_soportes(transacciones, candidatos)\n",
        "        # Generar Lk\n",
        "        Lk = [itemset for itemset in soporte_k if soporte_k[itemset] >= min_soporte]\n",
        "        # Actualizar soporte total\n",
        "        soporte_total.update(soporte_k)\n",
        "        frecuentes.append(Lk)\n",
        "        k += 1\n",
        "    return frecuentes, soporte_total\n",
        "\n",
        "# Ejecutar ambas versiones y comparar\n",
        "frecuentes_pruning, _ = apriori(transacciones, min_soporte)\n",
        "frecuentes_sin_pruning, _ = apriori_sin_pruning(transacciones, min_soporte)\n",
        "\n",
        "# Contar el número de candidatos generados en cada iteración\n",
        "def contar_candidatos(frecuentes):\n",
        "    counts = []\n",
        "    for k in range(len(frecuentes)):\n",
        "        counts.append(len(frecuentes[k]))\n",
        "    return counts\n",
        "\n",
        "counts_pruning = contar_candidatos(frecuentes_pruning)\n",
        "counts_sin_pruning = contar_candidatos(frecuentes_sin_pruning)\n",
        "\n",
        "print(\"Número de itemsets frecuentes con pruning:\", counts_pruning)\n",
        "print(\"Número de itemsets frecuentes sin pruning:\", counts_sin_pruning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdEz0TPo1Yej",
        "outputId": "02350e97-7342-4e26-c33b-1169d010fa39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de itemsets frecuentes con pruning: [4, 4, 0]\n",
            "Número de itemsets frecuentes sin pruning: [4, 4, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Salida:**\n",
        "\n",
        "```\n",
        "Número de itemsets frecuentes con pruning: [4, 4, 0]\n",
        "Número de itemsets frecuentes sin pruning: [4, 4, 0]\n",
        "```\n",
        "\n",
        "#### Análisis\n",
        "\n",
        "- **Con Pruning**:\n",
        "  - En la iteración de tamaño 3, solo se generó 1 itemset frecuente.\n",
        "- **Sin Pruning**:\n",
        "  - En la iteración de tamaño 3, se generaron 3 candidatos, pero solo 1 resultó ser frecuente.\n",
        "(Obs: Adaptar el ejemplo)\n",
        "\n",
        "**Conclusión**:\n",
        "\n",
        "- El pruning reduce el número de candidatos a considerar, ahorrando tiempo y recursos computacionales.\n",
        "- En conjuntos de datos más grandes, la diferencia en eficiencia es mucho más significativa.\n",
        "\n",
        "## 4.4 Exploración de Bibliotecas Populares\n",
        "\n",
        "Existen bibliotecas en Python que implementan el algoritmo Apriori de manera optimizada y fácil de usar. Dos de las más populares son **`apyori`** y **`mlxtend`**.\n",
        "\n",
        "### 4.4.1 Uso de `apyori` y `mlxtend` para Apriori\n",
        "\n",
        "#### Instalación de las Bibliotecas\n",
        "\n",
        "```bash\n",
        "pip install apyori\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "### 4.4.2 Implementación con Bibliotecas\n",
        "\n",
        "#### Uso de `apyori`"
      ],
      "metadata": {
        "id": "f_OMM8nE2Ao7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install apyori mlxtend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeyROSMo2HfG",
        "outputId": "31d68442-2c1a-4423-970d-c0421bbca0d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apyori\n",
            "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.23.1)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (3.8.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
            "Building wheels for collected packages: apyori\n",
            "  Building wheel for apyori (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5954 sha256=a24165653399d92fdde17e3cdc30e195dfdbe167d0aa4dabea9df88fb48ebc2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/1a/79/20f55c470a50bb3702a8cb7c94d8ada15573538c7f4baebe2d\n",
            "Successfully built apyori\n",
            "Installing collected packages: apyori\n",
            "Successfully installed apyori-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from apyori import apriori as apyori_apriori\n",
        "\n",
        "# Preparar los datos en el formato requerido (lista de listas)\n",
        "transacciones_lista = [list(transaccion) for transaccion in transacciones]\n",
        "\n",
        "# Ejecutar el algoritmo Apriori\n",
        "resultados = list(apyori_apriori(transacciones_lista, min_support=min_soporte))\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Itemsets frecuentes encontrados por apyori:\")\n",
        "for item in resultados:\n",
        "    items = set(item.items)\n",
        "    soporte = item.support\n",
        "    print(f\"{items}: {soporte:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-1Sq0942Afa",
        "outputId": "c82ddc2a-d3fc-4966-b97d-97e2f057c981"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Itemsets frecuentes encontrados por apyori:\n",
            "{'Cerveza'}: 0.80\n",
            "{'Leche'}: 0.80\n",
            "{'Pan'}: 0.80\n",
            "{'Pañales'}: 0.60\n",
            "{'Cerveza', 'Leche'}: 0.60\n",
            "{'Cerveza', 'Pan'}: 0.60\n",
            "{'Cerveza', 'Pañales'}: 0.60\n",
            "{'Pan', 'Leche'}: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Salida:**\n",
        "\n",
        "```\n",
        "Itemsets frecuentes encontrados por apyori:\n",
        "{'Leche'}: 0.80\n",
        "{'Pan'}: 0.80\n",
        "{'Cerveza'}: 0.80\n",
        "{'Leche', 'Pan'}: 0.60\n",
        "{'Leche', 'Cerveza'}: 0.60\n",
        "{'Pan', 'Cerveza'}: 0.60\n",
        "{'Leche', 'Pan', 'Cerveza'}: 0.40\n",
        "```\n",
        "\n",
        "#### Uso de `mlxtend`"
      ],
      "metadata": {
        "id": "FzxvAzeI2xgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori as mlxtend_apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "# Convertir las transacciones en un DataFrame de una matriz de ceros y unos\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transacciones_lista).transform(transacciones_lista)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Ejecutar Apriori\n",
        "frequent_itemsets = mlxtend_apriori(df, min_support=min_soporte, use_colnames=True)\n",
        "\n",
        "# Mostrar los itemsets frecuentes\n",
        "print(\"Itemsets frecuentes encontrados por mlxtend:\")\n",
        "print(frequent_itemsets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69DJF6aJ2xP2",
        "outputId": "fd543a0e-80c8-4406-fed0-9feaa4bcb592"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Itemsets frecuentes encontrados por mlxtend:\n",
            "   support            itemsets\n",
            "0      0.8           (Cerveza)\n",
            "1      0.8             (Leche)\n",
            "2      0.8               (Pan)\n",
            "3      0.6           (Pañales)\n",
            "4      0.6    (Cerveza, Leche)\n",
            "5      0.6      (Cerveza, Pan)\n",
            "6      0.6  (Cerveza, Pañales)\n",
            "7      0.6        (Pan, Leche)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Salida:**\n",
        "\n",
        "```\n",
        "Itemsets frecuentes encontrados por mlxtend:\n",
        "   support            itemsets\n",
        "0      0.8           (Cerveza)\n",
        "1      0.8             (Leche)\n",
        "2      0.8               (Pan)\n",
        "3      0.6           (Pañales)\n",
        "4      0.6    (Cerveza, Leche)\n",
        "5      0.6      (Cerveza, Pan)\n",
        "6      0.6  (Cerveza, Pañales)\n",
        "7      0.6        (Pan, Leche)\n",
        "```\n",
        "\n",
        "### 4.4.3 Comparación de Funcionalidades y Uso\n",
        "\n",
        "#### `apyori`\n",
        "\n",
        "- **Ventajas**:\n",
        "  - Fácil de usar con listas de transacciones.\n",
        "  - Devuelve reglas de asociación además de itemsets frecuentes.\n",
        "- **Desventajas**:\n",
        "  - Menos configurable.\n",
        "  - No tan eficiente en conjuntos de datos muy grandes.\n",
        "\n",
        "#### `mlxtend`\n",
        "\n",
        "- **Ventajas**:\n",
        "  - Altamente configurable y eficiente.\n",
        "  - Integra funciones para generar reglas de asociación.\n",
        "  - Utiliza estructuras de datos de pandas para mayor eficiencia.\n",
        "- **Desventajas**:\n",
        "  - Requiere convertir los datos a un formato de matriz binaria.\n",
        "  - Puede ser más complejo para principiantes.\n",
        "\n",
        "### 4.4.4 Ventajas y Desventajas de Implementación con Bibliotecas vs. Desde Cero\n",
        "\n",
        "#### Implementación con Bibliotecas\n",
        "\n",
        "**Ventajas**:\n",
        "\n",
        "- **Eficiencia**: Las bibliotecas están optimizadas para rendimiento.\n",
        "- **Facilidad de Uso**: Menos código y complejidad.\n",
        "- **Funciones Adicionales**: Herramientas integradas para análisis adicional.\n",
        "\n",
        "**Desventajas**:\n",
        "\n",
        "- **Menor Control**: Menos flexibilidad para personalizar el algoritmo.\n",
        "- **Caja Negra**: Menor comprensión de los detalles internos.\n",
        "\n",
        "#### Implementación Desde Cero\n",
        "\n",
        "**Ventajas**:\n",
        "\n",
        "- **Comprensión Profunda**: Mejora el entendimiento del algoritmo y su funcionamiento.\n",
        "- **Flexibilidad**: Posibilidad de modificar y adaptar el algoritmo a necesidades específicas.\n",
        "\n",
        "**Desventajas**:\n",
        "\n",
        "- **Complejidad**: Requiere más tiempo y esfuerzo para desarrollar.\n",
        "- **Eficiencia**: Puede ser menos eficiente si no se optimiza adecuadamente.\n",
        "\n",
        "## 4.5 Ejercicios Prácticos y Quiz\n",
        "\n",
        "### Ejercicio 1: Implementar Apriori con un Conjunto de Datos Propio\n",
        "\n",
        "Utilice un conjunto de transacciones propio o genere uno nuevo. Implemente el algoritmo Apriori desde cero y encuentre los itemsets frecuentes con un umbral de soporte mínimo de su elección.\n",
        "\n",
        "**Pasos**:\n",
        "\n",
        "1. Defina su conjunto de transacciones.\n",
        "2. Implemente el algoritmo siguiendo los pasos proporcionados.\n",
        "3. Compare sus resultados utilizando una biblioteca como `mlxtend`.\n",
        "\n",
        "### Ejercicio 2: Modificar el Algoritmo para Soportar Soporte Absoluto\n",
        "\n",
        "Actualmente, el algoritmo utiliza soporte relativo (fracción). Modifique la implementación para que pueda aceptar un soporte mínimo absoluto (número de transacciones).\n",
        "\n",
        "**Pistas**:\n",
        "\n",
        "- Ajuste la función de cálculo de soportes para trabajar con conteos absolutos.\n",
        "- Asegúrese de que el algoritmo funcione correctamente con el nuevo umbral.\n",
        "\n",
        "### Ejercicio 3: Análisis de Eficiencia con Datos Grandes\n",
        "\n",
        "Genere un conjunto de datos más grande (por ejemplo, 1000 transacciones con 20 ítems) y compare el tiempo de ejecución de su implementación desde cero con la de `mlxtend`.\n",
        "\n",
        "**Pasos**:\n",
        "\n",
        "1. Genere las transacciones aleatorias.\n",
        "2. Mida el tiempo de ejecución de ambas implementaciones.\n",
        "3. Analice los resultados y discuta las diferencias.\n",
        "\n",
        "### Quiz\n",
        "\n",
        "**Pregunta 1**: Explique el Teorema Apriori y cómo se utiliza en el algoritmo.\n",
        "\n",
        "**Respuesta**:\n",
        "\n",
        "El Teorema Apriori establece que si un itemset es frecuente, entonces todos sus subconjuntos también son frecuentes. En el algoritmo Apriori, se utiliza esta propiedad para eliminar candidatos que no pueden ser frecuentes, ya que si algún subconjunto de un candidato no es frecuente, el candidato completo tampoco lo será. Esto reduce significativamente el número de itemsets a evaluar.\n",
        "\n",
        "---\n",
        "\n",
        "**Pregunta 2**: ¿Cuál es la principal diferencia entre la generación de candidatos con y sin pruning?\n",
        "\n",
        "**Respuesta**:\n",
        "\n",
        "La principal diferencia es que con pruning se eliminan los candidatos cuyos subconjuntos no son frecuentes, basándose en el Teorema Apriori. Sin pruning, todos los posibles candidatos de tamaño \\( k \\) son generados y evaluados, incluyendo aquellos que no pueden ser frecuentes, lo que aumenta innecesariamente el espacio de búsqueda y el tiempo de cómputo.\n",
        "\n",
        "---\n",
        "\n",
        "**Pregunta 3**: ¿Por qué es importante comparar la implementación desde cero con el uso de bibliotecas?\n",
        "\n",
        "**Respuesta**:\n",
        "\n",
        "Comparar ambas implementaciones es importante para:\n",
        "\n",
        "- **Comprender a Fondo**: La implementación desde cero ayuda a entender los detalles y la lógica detrás del algoritmo.\n",
        "- **Evaluar Eficiencia**: Las bibliotecas suelen estar optimizadas; compararlas con una implementación propia muestra diferencias en rendimiento.\n",
        "- **Identificar Ventajas y Desventajas**: Ayuda a decidir cuándo es apropiado utilizar una biblioteca o una implementación personalizada según las necesidades.\n",
        "\n",
        "---\n",
        "\n",
        "**Pregunta 4**: ¿Qué ventajas ofrece `mlxtend` sobre `apyori` en el contexto de la minería de reglas de asociación?\n",
        "\n",
        "**Respuesta**:\n",
        "\n",
        "`mlxtend` ofrece mayor eficiencia y flexibilidad. Al utilizar estructuras de datos de pandas, puede manejar conjuntos de datos más grandes de manera más eficiente. Además, proporciona funciones adicionales para el análisis, como la generación de reglas de asociación con medidas como lift, leverage, etc. Por otro lado, `apyori` es más sencillo y fácil de usar para conjuntos de datos pequeños o para una introducción básica al algoritmo.\n",
        "\n",
        "---\n",
        "\n",
        "**Pregunta 5**: ¿Cómo afecta el tamaño del umbral mínimo de soporte al número de itemsets frecuentes encontrados?\n",
        "\n",
        "**Respuesta**:\n",
        "\n",
        "Un umbral mínimo de soporte más bajo resultará en más itemsets frecuentes, ya que se aceptan itemsets con menor frecuencia en las transacciones. Esto puede llevar a una explosión en el número de itemsets y aumentar la complejidad computacional. Un umbral más alto reduce el número de itemsets frecuentes, centrándose en los patrones más significativos pero corriendo el riesgo de perder información potencialmente útil.\n",
        "\n",
        "---\n",
        "\n",
        "## Resumen del Capítulo\n",
        "\n",
        "En este capítulo, hemos explorado en profundidad el **Algoritmo Apriori**:\n",
        "\n",
        "- **Fundamentos Teóricos**:\n",
        "  - Comprendimos el Teorema Apriori y cómo permite reducir el espacio de búsqueda.\n",
        "  - Analizamos la generación de candidatos y el proceso de pruning.\n",
        "\n",
        "- **Implementación Manual en Python**:\n",
        "  - Implementamos el algoritmo paso a paso desde cero.\n",
        "  - Observamos cómo aplicar el algoritmo en un conjunto de transacciones real.\n",
        "\n",
        "- **Análisis de Eficiencia y Mejora con Pruning**:\n",
        "  - Demostramos la importancia del pruning en la eficiencia del algoritmo.\n",
        "  - Comparación práctica entre las versiones con y sin pruning.\n",
        "\n",
        "- **Exploración de Bibliotecas Populares**:\n",
        "  - Aprendimos a usar `apyori` y `mlxtend` para ejecutar Apriori.\n",
        "  - Comparación de funcionalidades y discusión de ventajas y desventajas.\n",
        "\n",
        "- **Ejercicios Prácticos y Quiz**:\n",
        "  - Proporcionamos ejercicios para reforzar el aprendizaje y fomentar la práctica.\n",
        "  - Evaluamos la comprensión de los conceptos clave mediante preguntas y respuestas.\n",
        "\n",
        "Este capítulo es fundamental para entender cómo se extraen itemsets frecuentes de manera eficiente, sentando las bases para la generación de reglas de asociación y la aplicación de algoritmos más avanzados en capítulos posteriores.\n",
        "\n",
        "---\n",
        "\n",
        "## Referencias\n",
        "\n",
        "- Agrawal, R., & Srikant, R. (1994). Fast algorithms for mining association rules. *Proceedings of the 20th International Conference on Very Large Data Bases*, 487-499.\n",
        "- Han, J., Kamber, M., & Pei, J. (2011). *Data Mining: Concepts and Techniques*. Elsevier.\n",
        "- Raschka, S. (2018). *MLxtend: Providing machine learning and data science utilities and extensions to Python’s scientific computing stack*. *The Journal of Open Source Software*, 3(24), 638.\n",
        "\n",
        "---\n",
        "\n",
        "## Próximos Pasos\n",
        "\n",
        "En el siguiente capítulo, exploraremos la **Generación y Evaluación de Reglas de Asociación**, aprendiendo cómo convertir los itemsets frecuentes obtenidos mediante Apriori en reglas de asociación significativas y cómo evaluar su interés utilizando medidas como confianza, lift y otros.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "p4gwOZGhNeuR"
      }
    }
  ]
}